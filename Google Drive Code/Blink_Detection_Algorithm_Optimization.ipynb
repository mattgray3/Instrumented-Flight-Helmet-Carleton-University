{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "id": "K8iAigXNsTu8",
        "outputId": "b057143f-c8d0-43f7-cf0a-964d83dfc56c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (25.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Attempt Completed - Precision: 0.1734, Recall: 0.3388, F-beta: 0.2367, Weighted Score: -0.4576\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "No detected blinks to analyze.\n",
            "Attempt Completed - Precision: 0.5486, Recall: 0.1642, F-beta: 0.2405, Weighted Score: -0.5184\n",
            "No detected blinks to analyze.\n",
            "Attempt Completed - Precision: 0.6068, Recall: 0.6195, F-beta: 0.6137, Weighted Score: 0.2306\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-290888e22cd2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;31m# Execute Bayesian Optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m69\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0moptimal_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    279\u001b[0m         )\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-290888e22cd2>\u001b[0m in \u001b[0;36mobjective_function\u001b[0;34m(noise_threshold, symmetry_threshold, blink_trough_threshold, max_blink_duration, min_blink_duration, outlier_threshold, outlier_lowerbound, outlier_upperbound, likely_blink_percent, unlikey_blink_percent, min_duration_percent, max_duration_percent, symmetry_percent, amplitude_percent, tp_amplitude_threshold, tp_symmetry_threshold, likey_blink_factor, unlikey_blink_factor)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mscaled_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mPB_Dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trough_time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPB_Dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stable_points\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPB_Dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"amplitude\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentify_troughs_and_stable_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_signal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msearch_radius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrough_search_radius\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrough_proximity_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdup_trough_proximity_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mPB_Dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"duration_total\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPB_Dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"duration_opening\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPB_Dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"duration_closing\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPB_Dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"symmetry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPB_Dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"opening_velocity\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPB_Dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"closing_velocity\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_troughs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPB_Dictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Blink Detection/Code/blink_detection_functions.py\u001b[0m in \u001b[0;36midentify_troughs_and_stable_points\u001b[0;34m(signal, threshold, time_array, bandpassed_signal, search_radius, trough_proximity_threshold)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mbefore_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbefore_idx_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbefore_idx_arr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mafter_idx_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrough\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mafter_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafter_idx_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrough\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mafter_idx_arr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/multiarray.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(condition, x, y)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_from_c_func_and_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_multiarray_umath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \"\"\"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real\n",
        "from skopt.utils import use_named_args\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive for access\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ensure the blink_detection_functions module is on the path\n",
        "module_path = '/content/drive/MyDrive/Blink Detection/Code'\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "from blink_detection_functions import (bandpass_filter, remove_outliers, scale_signal, reduce_noise, identify_troughs_and_stable_points, analyze_troughs, identify_blinks, third_pass, validate_blinks)\n",
        "\n",
        "# Database connection\n",
        "db_path = '/content/drive/MyDrive/Blink Detection/Datasets/BLINKData_Labeled.db'\n",
        "conn = sqlite3.connect(db_path)\n",
        "tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)['name'].tolist()\n",
        "\n",
        "# Digital Filtering Settings\n",
        "lowcut = 0.3 # In HZ the lowcut used by the bandpass filter\n",
        "highcut = 28 # In Hz the highcut used by the bandpass filter\n",
        "sample_rate = 250 # The sampling date of the data you're using\n",
        "noise_threshold = 0.35444163267506573 # The systems removes any troughs smaller than the noise treshold to help make sure only blinks get through\n",
        "\n",
        "# Outliers\n",
        "outlier_threshold = 10 # Determines how far from the upper and lowerbound values that a point must be at to count as an outlier\n",
        "outlier_lowerbound = 56.3283293856677 # The percent that acts as the lower quartile for the signal\n",
        "outlier_upperbound = 87.05909901941988 # The percent that acts as the upper quartile for the signal\n",
        "\n",
        "# 2nd‑pass blink detection\n",
        "dup_trough_proximity_threshold = 0.3 # This settings makes sure that no troughs are being doubled counted in the data as anything within that time in seconds will be labeled only once\n",
        "symmetry_threshold = 51.1662910568745 # The lowest symetry allowed for a blink\n",
        "blink_trough_threshold = 0.1 # The minimum depth a trough can be to get scored as a blink\n",
        "max_blink_duration = 0.45 # The General Maximum Blink duration allowed in seconds\n",
        "min_blink_duration = 0.1 # The General Minimum Blink duration allowed in seconds\n",
        "\n",
        "# Blink‑likelihood weights\n",
        "min_duration_percent = 1.0 # Weight of score given if a blink is longer then minimum duration\n",
        "max_duration_percent = 64.37231191603038 # Weight of score given if a blink is shorter then maximum duration\n",
        "symmetry_percent = 99.0 # Weight of score given if a blink is within symmetry\n",
        "amplitude_percent = 7.69513579269388 # Weight of score given if a blink is within amplitude\n",
        "\n",
        "# 3rd‑pass tuning\n",
        "tp_amplitude_threshold = 2.0 # The width around the blink amplitude that is used to calculate the 3rd pass data\n",
        "tp_symmetry_threshold = 70.07846734816201 # The width around the symettry that is used to calculate the 3rd pass data\n",
        "likely_blink_percent = 100.0 # If a blink is over this liklihood is it considered high confidence and gets weighed more when calculating personal metrics\n",
        "unlikey_blink_percent = 0.0 # If a blink is under this liklihood is it considered low  confidence and gets weighed less when calculating personal metrics\n",
        "likey_blink_factor = 1.0 # If a blink is likely you can weight the new metrics to be closer to likly blinks\n",
        "unlikey_blink_factor = 0.1 # If a blink is unlikely you can weight the new metrics to be closer to likly blinks\n",
        "\n",
        "# Define the search space for Bayesian optimization\n",
        "search_space = [Real(0.0, 1.0,   name='noise_threshold'), Real(0.0, 100.0, name='symmetry_threshold'), Real(0.1, 1.5,   name='blink_trough_threshold'), Real(0.35, 0.8,  name='max_blink_duration'), Real(0.05, 0.105,name='min_blink_duration'), Real(0.0, 10.0,  name='outlier_threshold'), Real(0.0, 60.0,  name='outlier_lowerbound'), Real(70.0,100.0, name='outlier_upperbound'), Real(50.0, 100.0,name='likely_blink_percent'), Real(0.0, 49.0, name='unlikey_blink_percent'), Real(1.0, 99.0, name='min_duration_percent'), Real(1.0, 99.0, name='max_duration_percent'), Real(1.0, 99.0, name='symmetry_percent'), Real(1.0, 99.0, name='amplitude_percent'), Real(0.4, 2.0,   name='tp_amplitude_threshold'), Real(1.0, 100.0, name='tp_symmetry_threshold'), Real(1.0, 2.0,   name='likey_blink_factor'), Real(0.1, 0.9,   name='unlikey_blink_factor')]\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "@use_named_args(search_space)\n",
        "def objective_function(noise_threshold, symmetry_threshold, blink_trough_threshold, max_blink_duration, min_blink_duration, outlier_threshold, outlier_lowerbound, outlier_upperbound, likely_blink_percent, unlikey_blink_percent, min_duration_percent, max_duration_percent, symmetry_percent, amplitude_percent, tp_amplitude_threshold, tp_symmetry_threshold, likey_blink_factor, unlikey_blink_factor):\n",
        "\n",
        "    raw_weights = np.array([min_duration_percent, max_duration_percent, symmetry_percent, amplitude_percent])\n",
        "    normalized_weights = 100.0 * raw_weights / np.sum(raw_weights)\n",
        "\n",
        "    min_duration_percent = normalized_weights[0]\n",
        "    max_duration_percent = normalized_weights[1]\n",
        "    symmetry_percent = normalized_weights[2]\n",
        "    amplitude_percent = normalized_weights[3]\n",
        "\n",
        "    total_precision = 0\n",
        "    total_recall = 0\n",
        "    total_files = 0\n",
        "\n",
        "    for table in tables:\n",
        "        data = pd.read_sql(f\"SELECT * FROM [{table}]\", conn)\n",
        "        time_array = data['Time (s)'].values\n",
        "\n",
        "        blink_times = data[data['Blink'] == 1]['Time (s)']\n",
        "        total_actual_blinks = len(blink_times)\n",
        "\n",
        "        PB_Dictionary = {\"trough_time\": [], \"stable_points\": [], \"amplitude\": [], \"duration_opening\": [], \"duration_closing\": [], \"symmetry\": [], \"blink_likelyhood\": [], \"is_blink\": [], \"duration_total\": [], \"opening_velocity\": [], \"closing_velocity\": [], \"blink_validation\": [],}\n",
        "\n",
        "        filtered_signal = bandpass_filter(data['Voltage (V)'], lowcut, highcut, sample_rate)\n",
        "        filtered_signal = remove_outliers(filtered_signal, outlier_threshold, outlier_lowerbound, outlier_upperbound)\n",
        "        filtered_signal = scale_signal(filtered_signal)\n",
        "        scaled_signal = reduce_noise(filtered_signal, noise_threshold)\n",
        "\n",
        "        PB_Dictionary[\"trough_time\"], PB_Dictionary[\"stable_points\"], PB_Dictionary[\"amplitude\"] = identify_troughs_and_stable_points(scaled_signal, 0.2, time_array, filtered_signal,search_radius=trough_search_radius,trough_proximity_threshold=dup_trough_proximity_threshold)\n",
        "        PB_Dictionary[\"duration_total\"], PB_Dictionary[\"duration_opening\"], PB_Dictionary[\"duration_closing\"], PB_Dictionary[\"symmetry\"], PB_Dictionary[\"opening_velocity\"], PB_Dictionary[\"closing_velocity\"] = analyze_troughs(scaled_signal, PB_Dictionary)\n",
        "\n",
        "        PB_Dictionary[\"blink_likelyhood\"], PB_Dictionary[\"is_blink\"] = identify_blinks(PB_Dictionary, min_blink_duration, max_blink_duration, blink_trough_threshold, symmetry_threshold, min_duration_percent, max_duration_percent, symmetry_percent, amplitude_percent)\n",
        "\n",
        "        PB_Dictionary = third_pass(PB_Dictionary, tp_amplitude_threshold, tp_symmetry_threshold, \"iqr\", likely_blink_percent, unlikey_blink_percent, likey_blink_factor, unlikey_blink_factor)\n",
        "\n",
        "        for key, value in PB_Dictionary.items():\n",
        "            if isinstance(value, np.ndarray):\n",
        "                PB_Dictionary[key] = value.tolist()\n",
        "\n",
        "        PB_Dictionary = validate_blinks(PB_Dictionary, blink_times, proximity_threshold)\n",
        "\n",
        "        if isinstance(PB_Dictionary[\"blink_validation\"], np.ndarray):\n",
        "            PB_Dictionary[\"blink_validation\"] = PB_Dictionary[\"blink_validation\"].tolist()\n",
        "\n",
        "        validation = PB_Dictionary[\"blink_validation\"]\n",
        "        tp = validation.count(\"TP\")\n",
        "        fp = validation.count(\"FP\")\n",
        "        fn = validation.count(\"FN\")\n",
        "\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "        total_precision += precision\n",
        "        total_recall += recall\n",
        "        total_files += 1\n",
        "\n",
        "    avg_precision = total_precision / total_files if total_files > 0 else 0\n",
        "    avg_recall = total_recall / total_files if total_files > 0 else 0\n",
        "\n",
        "    beta = 1.1\n",
        "    if avg_precision + avg_recall == 0:\n",
        "        f_beta_score = 0\n",
        "    else:\n",
        "        f_beta_score = (1 + beta**2) * (avg_precision * avg_recall) / ((beta**2 * avg_precision) + avg_recall)\n",
        "\n",
        "    false_positive_penalty = 0.2\n",
        "    false_negative_penalty = 0.8\n",
        "\n",
        "    weighted_score = f_beta_score - (false_positive_penalty * (1 - avg_precision)) - (false_negative_penalty * (1 - avg_recall))\n",
        "\n",
        "    print(f\"Attempt Completed - Precision: {avg_precision:.4f}, Recall: {avg_recall:.4f}, F-beta: {f_beta_score:.4f}, Weighted Score: {weighted_score:.4f}\")\n",
        "\n",
        "    return -weighted_score\n",
        "\n",
        "# Execute Bayesian Optimization\n",
        "results = gp_minimize(func=objective_function, dimensions=search_space, n_calls=200, random_state=69 )\n",
        "\n",
        "optimal_params = {dim.name: value for dim, value in zip(search_space, results.x)}\n",
        "print(\"Optimal Parameters:\", optimal_params)\n",
        "best_weighted_score = -results.fun\n",
        "print(f\"Best Weighted Score: {best_weighted_score:.4f}\")"
      ]
    }
  ]
}